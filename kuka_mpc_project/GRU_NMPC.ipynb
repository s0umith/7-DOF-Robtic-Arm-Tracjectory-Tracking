{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldy3NxoJEM2z"
      },
      "outputs": [],
      "source": [
        "\n",
        "1pip install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpiMkb_NEMmt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV9YEIYA6r2A",
        "outputId": "ed40df21-4397-4978-a23f-6691246073f8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 9 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully from ./gruGA_datacombID.keras\n",
            "Scaler loaded successfully from ./scaler.pkl\n",
            "Reference trajectory loaded from ./kukatraj10.csv, shape: (1996, 35)\n",
            "Starting MPC...\n",
            "Calculated total MPC steps: 100\n",
            "Using n_jobs=-1 for parallel gradient calculation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MPC Iter 0/100 (Solving):   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "MPC Iter 1/100 (Solving):   1%|          | 1/100 [2:17:00<226:03:20, 8220.21s/it, Last Time: 8220.102s, Status: Maximum number of iterations exceeded (can be specified by an option).]   "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: IPOPT finished iteration 0 with status -1 (Maximum number of iterations exceeded (can be specified by an option).).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MPC Iter 1/100 (Simulating):   2%|▏         | 2/100 [4:30:59<220:52:19, 8113.67s/it, Last Time: 8038.889s, Status: Maximum number of iterations exceeded (can be specified by an option).]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Warning: IPOPT finished iteration 1 with status -1 (Maximum number of iterations exceeded (can be specified by an option).).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rMPC Iter 2/100 (Solving):   2%|▏         | 2/100 [4:30:59<220:52:19, 8113.67s/it, Last Time: 8038.889s, Status: Maximum number of iterations exceeded (can be specified by an option).]   "
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import cyipopt as ipopt\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "# Import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load Model, Scaler Object, and Recreate Encoder ---\n",
        "# (Same as before)\n",
        "drive_path = './'\n",
        "model_path = os.path.join(drive_path, 'gruGA_datacombID.keras')\n",
        "scaler_path = os.path.join(drive_path, 'scaler.pkl')\n",
        "\n",
        "try:\n",
        "    model = load_model(model_path)\n",
        "    print(f\"Model loaded successfully from {model_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Keras model: {e}\")\n",
        "    exit()\n",
        "\n",
        "try:\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    print(f\"Scaler loaded successfully from {scaler_path}\")\n",
        "    full_mean = scaler.mean_\n",
        "    full_scale = scaler.scale_\n",
        "    Xphys_mean = full_mean[:21]\n",
        "    Xphys_std = full_scale[:21]\n",
        "    y_mean = full_mean[21:]\n",
        "    y_std = full_scale[21:]\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Scaler file not found at {scaler_path}. Please ensure it exists.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading scaler: {e}\")\n",
        "    exit()\n",
        "\n",
        "NUM_TRAJECTORIES = 10\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "traj_ids = np.arange(NUM_TRAJECTORIES).reshape(-1, 1)\n",
        "encoder.fit(traj_ids)\n",
        "\n",
        "# --- MPC Parameters ---\n",
        "# (Same as before)\n",
        "delta = 0.01\n",
        "NUM_MPC_ITERATION = 100 # Max iterations to attempt\n",
        "NUM_PHYSICAL_FEATURES = 21\n",
        "NUM_GRU_INPUT_FEATURES = NUM_PHYSICAL_FEATURES + NUM_TRAJECTORIES # 31\n",
        "NUM_STATE_VARIABLES = 14\n",
        "NUM_CONTROL_INPUTS = 7\n",
        "NUM_GRU_OUTPUTS = 14\n",
        "SEQ_LENGTH = 10\n",
        "HORIZON = 5\n",
        "NUM_MPC_OPTIMIZATION_VARS = NUM_CONTROL_INPUTS * HORIZON\n",
        "NUM_MPC_CONSTRAINTS = 0\n",
        "\n",
        "# --- Reference Trajectory ---\n",
        "# (Same as before)\n",
        "ref_traj_file = os.path.join(drive_path, 'kukatraj10.csv')\n",
        "try:\n",
        "    ref_df = pd.read_csv(ref_traj_file)\n",
        "    reference_trajectory_full = ref_df.values\n",
        "    print(f\"Reference trajectory loaded from {ref_traj_file}, shape: {reference_trajectory_full.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Reference trajectory file not found at {ref_traj_file}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error reading reference trajectory: {e}\")\n",
        "    exit()\n",
        "\n",
        "ref_traj_id = 9\n",
        "ref_traj_one_hot = encoder.transform([[ref_traj_id]])\n",
        "reference_states_full = reference_trajectory_full[:, 21:35]\n",
        "\n",
        "# --- Initial State ---\n",
        "# (Same as before)\n",
        "if len(reference_trajectory_full) < SEQ_LENGTH:\n",
        "    print(f\"Error: Reference trajectory length ({len(reference_trajectory_full)}) is less than sequence length ({SEQ_LENGTH}).\")\n",
        "    exit()\n",
        "initial_state = reference_trajectory_full[SEQ_LENGTH - 1, 0:14]\n",
        "initial_sequence_physical = reference_trajectory_full[0:SEQ_LENGTH, 0:21]\n",
        "initial_sequence_onehot = np.tile(ref_traj_one_hot, (SEQ_LENGTH, 1))\n",
        "current_gru_input_sequence = np.hstack((initial_sequence_physical, initial_sequence_onehot))\n",
        "\n",
        "# --- Global variables ---\n",
        "# (Same as before)\n",
        "global_current_state = initial_state.copy()\n",
        "global_current_gru_input_sequence = current_gru_input_sequence.copy()\n",
        "mpc_step_index = 0\n",
        "\n",
        "# --- Manual Scaling/Inverse Scaling Functions ---\n",
        "# (Same as before)\n",
        "def scale_physical_inputs(data_phys_unscaled, mean_vec, std_vec):\n",
        "    return (data_phys_unscaled - mean_vec) / (std_vec + 1e-8)\n",
        "\n",
        "def inverse_scale_outputs(data_scaled, mean_vec, std_vec):\n",
        "    return data_scaled * (std_vec + 1e-8) + mean_vec\n",
        "\n",
        "# --- GRU Prediction Function (Helper for callbacks) ---\n",
        "# (Same as before)\n",
        "def predict_horizon(current_input_sequence_unscaled, control_sequence_horizon_unscaled, ref_one_hot):\n",
        "    predicted_states_horizon_unscaled = np.zeros((HORIZON, NUM_GRU_OUTPUTS))\n",
        "    temp_input_sequence_unscaled = current_input_sequence_unscaled.copy()\n",
        "    reshaped_controls_unscaled = control_sequence_horizon_unscaled.reshape(HORIZON, NUM_CONTROL_INPUTS)\n",
        "    for i in range(HORIZON):\n",
        "        physical_part_unscaled = temp_input_sequence_unscaled[:, :NUM_PHYSICAL_FEATURES]\n",
        "        one_hot_part = temp_input_sequence_unscaled[:, NUM_PHYSICAL_FEATURES:]\n",
        "        scaled_physical_part = scale_physical_inputs(physical_part_unscaled, Xphys_mean, Xphys_std)\n",
        "        scaled_input_sequence_step = np.hstack((scaled_physical_part, one_hot_part))\n",
        "        gru_input = scaled_input_sequence_step.reshape(1, SEQ_LENGTH, NUM_GRU_INPUT_FEATURES)\n",
        "        scaled_predicted_output = model.predict(gru_input, verbose=0)\n",
        "        predicted_output_unscaled = inverse_scale_outputs(scaled_predicted_output, y_mean, y_std)\n",
        "        predicted_states_horizon_unscaled[i, :] = predicted_output_unscaled[0]\n",
        "        next_pos_vel_unscaled = predicted_output_unscaled[0]\n",
        "        current_torques_unscaled = reshaped_controls_unscaled[i, :]\n",
        "        next_physical_features_unscaled = np.concatenate((next_pos_vel_unscaled, current_torques_unscaled))\n",
        "        next_full_input_step_unscaled = np.concatenate((next_physical_features_unscaled, ref_one_hot[0]))\n",
        "        temp_input_sequence_unscaled = np.vstack((temp_input_sequence_unscaled[1:], next_full_input_step_unscaled))\n",
        "    return predicted_states_horizon_unscaled\n",
        "\n",
        "# --- Define the Problem Class for cyipopt ---\n",
        "# (Same as before, including parallel gradient)\n",
        "class MPCProblem:\n",
        "    def __init__(self, n_jobs=-1):\n",
        "        self.n_jobs = n_jobs\n",
        "        self.finite_diff_step = 1e-4\n",
        "\n",
        "    def objective(self, x_unscaled):\n",
        "        global global_current_gru_input_sequence, reference_states_full, mpc_step_index, ref_traj_one_hot\n",
        "        predicted_states_unscaled = predict_horizon(global_current_gru_input_sequence, x_unscaled, ref_traj_one_hot)\n",
        "        start_ref_idx = mpc_step_index + 1\n",
        "        end_ref_idx = start_ref_idx + HORIZON\n",
        "        actual_horizon_len = HORIZON\n",
        "        if end_ref_idx > len(reference_states_full):\n",
        "            end_ref_idx = len(reference_states_full)\n",
        "            actual_horizon_len = end_ref_idx - start_ref_idx\n",
        "            if actual_horizon_len < HORIZON and actual_horizon_len >= 0:\n",
        "                 predicted_states_unscaled = predicted_states_unscaled[:actual_horizon_len, :]\n",
        "            elif actual_horizon_len < 0:\n",
        "                 return 0.0\n",
        "        if actual_horizon_len <= 0: return 0.0\n",
        "        reference_states_horizon_unscaled = reference_states_full[start_ref_idx:end_ref_idx, :]\n",
        "        if predicted_states_unscaled.shape[0] != reference_states_horizon_unscaled.shape[0]:\n",
        "            min_len = min(predicted_states_unscaled.shape[0], reference_states_horizon_unscaled.shape[0])\n",
        "            if min_len <= 0: return 0.0\n",
        "            cost = np.sum((predicted_states_unscaled[:min_len, :] - reference_states_horizon_unscaled[:min_len, :])**2)\n",
        "        else:\n",
        "            cost = np.sum((predicted_states_unscaled - reference_states_horizon_unscaled)**2)\n",
        "        return cost\n",
        "\n",
        "    def gradient(self, x_unscaled):\n",
        "        n = len(x_unscaled)\n",
        "        step = self.finite_diff_step\n",
        "        def compute_obj_diff(i, x_base):\n",
        "            x_plus = x_base.copy()\n",
        "            x_minus = x_base.copy()\n",
        "            x_plus[i] += step\n",
        "            x_minus[i] -= step\n",
        "            f_plus = self.objective(x_plus)\n",
        "            f_minus = self.objective(x_minus)\n",
        "            return f_plus - f_minus\n",
        "        diffs = Parallel(n_jobs=self.n_jobs)(delayed(compute_obj_diff)(i, x_unscaled) for i in range(n))\n",
        "        grad = np.array(diffs) / (2 * step)\n",
        "        return grad\n",
        "\n",
        "    def constraints(self, x_unscaled):\n",
        "        assert NUM_MPC_CONSTRAINTS == 0, \"Constraint function not implemented\"\n",
        "        return np.array([])\n",
        "\n",
        "    def jacobianstructure(self):\n",
        "        assert NUM_MPC_CONSTRAINTS == 0, \"Jacobian structure not needed\"\n",
        "        return (np.array([], dtype=int), np.array([], dtype=int))\n",
        "\n",
        "    def jacobian(self, x_unscaled):\n",
        "        assert NUM_MPC_CONSTRAINTS == 0, \"Jacobian calculation not needed\"\n",
        "        return np.array([])\n",
        "\n",
        "# --- IPOPT Setup ---\n",
        "# (Same as before)\n",
        "nvar = NUM_MPC_OPTIMIZATION_VARS\n",
        "ncon = NUM_MPC_CONSTRAINTS\n",
        "torque_lower_limit = -10.0\n",
        "torque_upper_limit = 10.0\n",
        "lb = np.full(nvar, torque_lower_limit)\n",
        "ub = np.full(nvar, torque_upper_limit)\n",
        "cl = np.array([])\n",
        "cu = np.array([])\n",
        "\n",
        "# --- MPC Loop ---\n",
        "actual_states_history = [initial_state]\n",
        "applied_torques_history = []\n",
        "mpc_computation_time = []\n",
        "x0 = np.zeros(nvar)\n",
        "\n",
        "print(\"Starting MPC...\")\n",
        "\n",
        "min_required_len = SEQ_LENGTH + HORIZON\n",
        "if len(reference_trajectory_full) < min_required_len:\n",
        "     print(f\"Error: Reference trajectory too short ({len(reference_trajectory_full)}) for sequence length ({SEQ_LENGTH}) and horizon ({HORIZON}). Needs {min_required_len} steps.\")\n",
        "     total_steps = 0\n",
        "else:\n",
        "    max_possible_steps = len(reference_trajectory_full) - SEQ_LENGTH - HORIZON + 1\n",
        "    total_steps = min(NUM_MPC_ITERATION, max_possible_steps)\n",
        "\n",
        "print(f\"Calculated total MPC steps: {total_steps}\")\n",
        "num_cores_to_use = -1\n",
        "print(f\"Using n_jobs={num_cores_to_use} for parallel gradient calculation.\")\n",
        "\n",
        "# Initialize tqdm progress bar before the loop [6]\n",
        "pbar = tqdm(total=total_steps, desc=\"Starting MPC...\")\n",
        "\n",
        "try: # Use try...finally to ensure pbar is closed\n",
        "    for k in range(total_steps):\n",
        "        # Update global step index for callbacks\n",
        "        mpc_step_index = k\n",
        "\n",
        "        # Update tqdm description to show current iteration [8]\n",
        "        pbar.set_description(f\"MPC Iter {k}/{total_steps} (Solving)\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        global_current_gru_input_sequence = current_gru_input_sequence\n",
        "\n",
        "        # --- Create cyipopt Problem ---\n",
        "        problem_obj = MPCProblem(n_jobs=num_cores_to_use)\n",
        "        nlp = ipopt.Problem(n=nvar, m=ncon, problem_obj=problem_obj, lb=lb, ub=ub, cl=cl, cu=cu)\n",
        "\n",
        "        # --- Set IPOPT Options ---\n",
        "        nlp.add_option('max_iter', 200)\n",
        "        nlp.add_option('tol', 1e-4)\n",
        "        nlp.add_option('print_level', 0) # Keep low to avoid interfering with tqdm\n",
        "        nlp.add_option('hessian_approximation', 'limited-memory')\n",
        "\n",
        "        # --- Solve the Optimization Problem ---\n",
        "        try:\n",
        "            x_opt_unscaled, info = nlp.solve(x0)\n",
        "            status = info['status']\n",
        "            obj = info['obj_val']\n",
        "        except Exception as e:\n",
        "            print(f\"\\n!!! IPOPT solve failed in iteration {k} with exception: {e}\")\n",
        "            print(\"Stopping MPC loop.\")\n",
        "            break # Exit the main loop\n",
        "\n",
        "        end_time = time.time()\n",
        "        iter_time = end_time - start_time\n",
        "        mpc_computation_time.append(iter_time)\n",
        "\n",
        "        # Update tqdm postfix with last iteration time and solver status [6]\n",
        "        status_msg = info['status_msg'].decode()\n",
        "        pbar.set_postfix_str(f\"Last Time: {iter_time:.3f}s, Status: {status_msg}\")\n",
        "\n",
        "        # (Optional) Print warning if solver status is not optimal/acceptable\n",
        "        if status < 0:\n",
        "             print(f\"\\nWarning: IPOPT finished iteration {k} with status {status} ({status_msg}).\")\n",
        "\n",
        "        # --- Extract controls and Simulate ---\n",
        "        pbar.set_description(f\"MPC Iter {k}/{total_steps} (Simulating)\") # Update description\n",
        "\n",
        "        optimal_torques_unscaled = x_opt_unscaled[0:NUM_CONTROL_INPUTS]\n",
        "        applied_torques_history.append(optimal_torques_unscaled)\n",
        "\n",
        "        # (Simulation code remains the same)\n",
        "        current_physical_input_unscaled = np.concatenate((global_current_state, optimal_torques_unscaled))\n",
        "        current_full_input_step_unscaled = np.concatenate((current_physical_input_unscaled, ref_traj_one_hot[0]))\n",
        "        sim_input_sequence_unscaled = np.vstack((current_gru_input_sequence[1:], current_full_input_step_unscaled))\n",
        "        sim_physical_part_unscaled = sim_input_sequence_unscaled[:, :NUM_PHYSICAL_FEATURES]\n",
        "        sim_one_hot_part = sim_input_sequence_unscaled[:, NUM_PHYSICAL_FEATURES:]\n",
        "        sim_scaled_physical_part = scale_physical_inputs(sim_physical_part_unscaled, Xphys_mean, Xphys_std)\n",
        "        sim_scaled_input_sequence = np.hstack((sim_scaled_physical_part, sim_one_hot_part))\n",
        "        gru_sim_input = sim_scaled_input_sequence.reshape(1, SEQ_LENGTH, NUM_GRU_INPUT_FEATURES)\n",
        "        scaled_next_state = model.predict(gru_sim_input, verbose=0)\n",
        "        next_state_unscaled = inverse_scale_outputs(scaled_next_state, y_mean, y_std)[0]\n",
        "        global_current_state = next_state_unscaled\n",
        "        current_gru_input_sequence = sim_input_sequence_unscaled\n",
        "        actual_states_history.append(global_current_state)\n",
        "\n",
        "        # --- Update initial guess (Warm Start) ---\n",
        "        x0 = np.roll(x_opt_unscaled, -NUM_CONTROL_INPUTS)\n",
        "        x0[-NUM_CONTROL_INPUTS:] = x_opt_unscaled[-NUM_CONTROL_INPUTS:]\n",
        "\n",
        "        # --- Update the progress bar for the completed iteration ---\n",
        "        pbar.update(1)\n",
        "\n",
        "finally:\n",
        "    pbar.close() # Ensure the progress bar is closed cleanly [6]\n",
        "\n",
        "print(\"\\nMPC Finished.\")\n",
        "\n",
        "# --- Analysis ---\n",
        "# (Plotting code remains the same)\n",
        "if mpc_computation_time:\n",
        "    print(f\"Average MPC computation time per iteration: {np.mean(mpc_computation_time):.4f} seconds\")\n",
        "\n",
        "if len(actual_states_history) > 1:\n",
        "    actual_states_history = np.array(actual_states_history)\n",
        "    applied_torques_history = np.array(applied_torques_history)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    num_joints_to_plot = 7\n",
        "    plot_time_steps = len(actual_states_history)\n",
        "    time_axis = np.arange(plot_time_steps)\n",
        "    ref_start_idx = SEQ_LENGTH - 1\n",
        "    ref_indices = np.arange(ref_start_idx, ref_start_idx + plot_time_steps)\n",
        "\n",
        "    for i in range(num_joints_to_plot):\n",
        "        plt.subplot(num_joints_to_plot, 1, i+1)\n",
        "        plt.plot(time_axis, actual_states_history[:, i], label=f'Actual Joint {i+1} Pos', linewidth=2)\n",
        "        valid_ref_indices = ref_indices[ref_indices < len(reference_trajectory_full)]\n",
        "        ref_time_axis = time_axis[:len(valid_ref_indices)]\n",
        "        plt.plot(ref_time_axis, reference_trajectory_full[valid_ref_indices, i], '--', label=f'Reference Joint {i+1} Pos', linewidth=2)\n",
        "        plt.ylabel(f'Joint {i+1}')\n",
        "        plt.grid(True)\n",
        "        if i == 0:\n",
        "            plt.title('MPC Tracking Performance (Unscaled Joint Positions)')\n",
        "            plt.legend(loc='upper right')\n",
        "        if i == num_joints_to_plot - 1:\n",
        "            plt.xlabel('Time Step (k)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    torque_time_axis = np.arange(len(applied_torques_history))\n",
        "    for i in range(NUM_CONTROL_INPUTS):\n",
        "         plt.plot(torque_time_axis, applied_torques_history[:, i], label=f'Torque Joint {i+1}')\n",
        "    plt.title('Applied Unscaled Torques by MPC')\n",
        "    plt.xlabel('Time Step (k)')\n",
        "    plt.ylabel('Torque')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"MPC did not complete enough steps to generate plots.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}